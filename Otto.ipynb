{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, ParameterGrid\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix, auc\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = read_csv('train.csv')\n",
    "#test_data = read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61878, 95)\n"
     ]
    }
   ],
   "source": [
    "# Training data dimensions\n",
    "print(train_data.shape)\n",
    "#print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>47044</td>\n",
       "      <td>47045</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19151</td>\n",
       "      <td>19152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46686</td>\n",
       "      <td>46687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2543</td>\n",
       "      <td>2544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1108</td>\n",
       "      <td>1109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46527</td>\n",
       "      <td>46528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Class_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>702</td>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22028</td>\n",
       "      <td>22029</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30460</td>\n",
       "      <td>30461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36525</td>\n",
       "      <td>36526</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "47044  47045       0       0       0       0       0       0       3       0   \n",
       "19151  19152       0       0       0       0       0       0       0       0   \n",
       "46686  46687       0       0       0       0       0       0       0       0   \n",
       "2543    2544       0       0       0       0       0       0       0       0   \n",
       "1108    1109       0       0       0       0       0       0       0       1   \n",
       "46527  46528       0       0       0       0       0       0       1       1   \n",
       "702      703       1       0       0       0       0       0       0       6   \n",
       "22028  22029       1       0       0       0       0       0       0       1   \n",
       "30460  30461       0       0       0       0       0       0       0       1   \n",
       "36525  36526       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       feat_9  ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  \\\n",
       "47044       0  ...        3        1        2        1        0        0   \n",
       "19151       0  ...        0        0        0        1        0        0   \n",
       "46686       0  ...        0        0        0        0        0        2   \n",
       "2543        0  ...        0        2        1        0        0        0   \n",
       "1108        0  ...        0        0        0        0        0        0   \n",
       "46527       0  ...        2        0        3        0        0        0   \n",
       "702         0  ...        0        0        0        0        1        0   \n",
       "22028       0  ...        0        1        0        0        0        0   \n",
       "30460       0  ...        0        0        0        0        0        0   \n",
       "36525       0  ...        0        0        0        1        0        0   \n",
       "\n",
       "       feat_91  feat_92  feat_93   target  \n",
       "47044        0        0        0  Class_7  \n",
       "19151        0        0        0  Class_3  \n",
       "46686        0        0        0  Class_7  \n",
       "2543         0        1        0  Class_2  \n",
       "1108         0        0        0  Class_1  \n",
       "46527        0        0        1  Class_7  \n",
       "702          0        0        0  Class_1  \n",
       "22028        0        0        0  Class_3  \n",
       "30460        0        0        0  Class_5  \n",
       "36525        0        0        0  Class_6  \n",
       "\n",
       "[10 rows x 95 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAMPLE 10 Rows from training dataset\n",
    "train_data.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each *column* represents a feature measured by an integer. Each *row* is an **Otto** product.\n",
    "The **Class Labels (targets)** are provided as character string in the last column. The **Otto** challenge is a multi class classification challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          int64\n",
       "feat_1      int64\n",
       "feat_2      int64\n",
       "feat_3      int64\n",
       "feat_4      int64\n",
       "            ...  \n",
       "feat_90     int64\n",
       "feat_91     int64\n",
       "feat_92     int64\n",
       "feat_93     int64\n",
       "target     object\n",
       "Length: 95, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking datatypes of Training columns\n",
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Features \n",
      " [[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 3 10 0]\n",
      " [0 0 0 ... 0 2 0]] \n",
      "\n",
      " Target Labels \n",
      " ['Class_1' 'Class_1' 'Class_1' ... 'Class_9' 'Class_9' 'Class_9']\n"
     ]
    }
   ],
   "source": [
    "# split data into X(features) and y(target labels)\n",
    "X = train_data.values[:, 1:94]\n",
    "y = train_data.values[:,94]\n",
    "\n",
    "print(\"Input Features \\n\", X, \"\\n\\n Target Labels \\n\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are provided as character string in the **target column**. **XGBoost** doesn't support anything else than numbers. So we will convert classes to integers. Moreover, according to the documentation, it should start at 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 8 8 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode string class values as integers, a\n",
    "label_encoded_y = LabelEncoder().fit_transform(y)\n",
    "print(label_encoded_y)\n",
    "\n",
    "# Check no. of unique labels\n",
    "np.unique(label_encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Splitting data into train and test sets\"\"\"\n",
    "train_X, valid_X, train_labels, valid_labels = model_selection.train_test_split(X, label_encoded_y,\n",
    "                                                                                shuffle=True, test_size=0.20,\n",
    "                                                                                random_state=42, \n",
    "                                                                                stratify= label_encoded_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the learning we will use the cross validation to evaluate the our error rate.\n",
    "\n",
    "Basically **XGBoost** will divide the training data in `nfold` parts, then **XGBoost** will retain the first part and use it as the test data. Then it will reintegrate the first part to the training dataset and retain the second part, do a training and so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Thread XGBoost, Parallel Thread Cross-Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building GRID SEARCH \n",
    "GS_model = XGBClassifier(objective= \"multi:softprob\",booster='gbtree',  n_jobs=-1)\n",
    "\n",
    "subsample = [0.80, 1]\n",
    "#learning_rate = [0.1, 0.2]\n",
    "#max_depth = [2,3]\n",
    "#min_child_weight = [1, 1.2]\n",
    "#gamma = [0, 0.15]\n",
    "\n",
    "param_grid = dict(subsample = subsample)\n",
    "pg = ParameterGrid(param_grid)\n",
    "len(pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:  2.4min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.651856 using {'subsample': 0.8}\n",
      "Parallel Thread XGBoost, Parallel Thread CV: 304.441287\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "kfold = StratifiedKFold(n_splits = 3, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(GS_model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold, verbose=1)\n",
    "grid_result = grid_search.fit(train_X, train_labels)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "elapsed = time.time() - start\n",
    "print(\"Parallel Thread XGBoost, Parallel Thread CV, Elapsed Time: %f\" % (elapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.651856 using {'subsample': 0.8}\n",
      "-0.651856 (0.002537) with: {'subsample': 0.8}\n",
      "-0.658526 (0.001935) with: {'subsample': 1}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12376, 12376)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_X), len(valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Thread XGBoost, Single Thread Cross-Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 10.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.651856 using {'subsample': 0.8}\n",
      "Parallel Thread XGBoost, Parallel Thread CV, Elapsed Time: 782.629930\n"
     ]
    }
   ],
   "source": [
    "# Building GRID SEARCH \n",
    "GS_model = XGBClassifier(objective= \"multi:softprob\",booster='gbtree',  n_jobs=1)\n",
    "\n",
    "subsample = [0.80, 1]\n",
    "#learning_rate = [0.1, 0.2]\n",
    "#max_depth = [2,3]\n",
    "#min_child_weight = [1, 1.2]\n",
    "#gamma = [0, 0.15]\n",
    "\n",
    "param_grid = dict(subsample = subsample)\n",
    "pg = ParameterGrid(param_grid)\n",
    "print(len(pg))\n",
    "\n",
    "start = time.time()\n",
    "kfold = StratifiedKFold(n_splits = 3, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(GS_model, param_grid, scoring=\"neg_log_loss\", n_jobs=1, cv=kfold, verbose=1)\n",
    "grid_result = grid_search.fit(train_X, train_labels)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "elapsed = time.time() - start\n",
    "print(\"Parallel Thread XGBoost, Parallel Thread CV, Elapsed Time: %f\" % (elapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.651856 using {'subsample': 0.8}\n",
      "-0.651856 (0.002537) with: {'subsample': 0.8}\n",
      "-0.658526 (0.001935) with: {'subsample': 1}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that the Running Time without multithreading  is 782.629 more than twice longer than using Parallel Threads (i.e. all 6 cores of the local CPU) where the Running Time was 304.44."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(n_jobs = -1,subsample=0.8, n_estimators=100, learning_rate=0.1)\n",
    "clf.fit(train_X, train_labels, early_stopping_rounds=100, eval_set = [(train_X, train_labels),(valid_X, valid_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8149644473173885\n",
      "Precision: 0.8102997951687697 0.8149644473173885 0.8120801411848321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.54      0.61       386\n",
      "           1       0.73      0.85      0.79      3224\n",
      "           2       0.62      0.50      0.55      1601\n",
      "           3       0.79      0.51      0.62       538\n",
      "           4       0.98      0.98      0.98       548\n",
      "           5       0.94      0.94      0.94      2827\n",
      "           6       0.77      0.68      0.72       568\n",
      "           7       0.92      0.94      0.93      1693\n",
      "           8       0.85      0.88      0.86       991\n",
      "\n",
      "    accuracy                           0.81     12376\n",
      "   macro avg       0.81      0.76      0.78     12376\n",
      "weighted avg       0.81      0.81      0.81     12376\n",
      "\n",
      "[[ 207    8    0    0    1   35   13   45   77]\n",
      " [   6 2755  369   44    6    8   24    5    7]\n",
      " [   2  755  798   15    0    0   23    4    4]\n",
      " [   0  153   90  274    4   13    3    0    1]\n",
      " [   0    7    0    1  539    1    0    0    0]\n",
      " [   9   25    4    4    0 2661   43   47   34]\n",
      " [  16   57   32    8    1   45  387   14    8]\n",
      " [  20   11    3    0    0   35    8 1594   22]\n",
      " [  33   18    1    0    1   33    2   32  871]]\n"
     ]
    }
   ],
   "source": [
    "predict = clf.predict(valid_X)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(valid_labels, predict))\n",
    "print(\"Precision:\", precision_score(valid_labels, predict, average='macro'),\n",
    "      precision_score(valid_labels, predict, average='micro'), precision_score(valid_labels, predict, average='weighted'))\n",
    "print(classification_report(valid_labels, predict))\n",
    "print(confusion_matrix(valid_labels, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the effect of the number of threads(parallelism)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "num_threads = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of parallel threads: 1 Learning Time: 149.97723603248596\n",
      "Accuracy: 0.8149644473173885\n",
      "No. of parallel threads: 2 Learning Time: 77.43907570838928\n",
      "Accuracy: 0.8149644473173885\n",
      "No. of parallel threads: 3 Learning Time: 53.191312313079834\n",
      "Accuracy: 0.8149644473173885\n",
      "No. of parallel threads: 4 Learning Time: 46.35785508155823\n",
      "Accuracy: 0.8149644473173885\n",
      "No. of parallel threads: 5 Learning Time: 39.77633881568909\n",
      "Accuracy: 0.8149644473173885\n",
      "No. of parallel threads: 6 Learning Time: 43.05844187736511\n",
      "Accuracy: 0.8149644473173885\n",
      "No. of parallel threads: 7 Learning Time: 40.28342413902283\n",
      "Accuracy: 0.8149644473173885\n",
      "No. of parallel threads: 8 Learning Time: 37.92302203178406\n",
      "Accuracy: 0.8149644473173885\n",
      "No. of parallel threads: 9 Learning Time: 35.177626848220825\n",
      "Accuracy: 0.8149644473173885\n",
      "No. of parallel threads: 10 Learning Time: 32.675058126449585\n",
      "Accuracy: 0.8149644473173885\n",
      "No. of parallel threads: 11 Learning Time: 32.334880113601685\n",
      "Accuracy: 0.8149644473173885\n",
      "No. of parallel threads: 12 Learning Time: 31.725539207458496\n",
      "Accuracy: 0.8149644473173885\n"
     ]
    }
   ],
   "source": [
    "for n in num_threads:\n",
    "    start = time.time()\n",
    "    model = XGBClassifier(n_jobs=n, subsample=0.8)\n",
    "    model.fit(train_X, train_labels)\n",
    "    elapsed = time.time() - start\n",
    "    print(\"No. of parallel threads:\", n,\"Learning Time:\", elapsed)\n",
    "    results.append(elapsed)\n",
    "    model_predict = model.predict(valid_X)\n",
    "    #print(classification_report(valid_labels, model_predict))\n",
    "    print(\"Accuracy:\", accuracy_score(valid_labels, predict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Learning Time vs Number of Threads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot Evaluation results\n",
    "pyplot.plot(num_threads, results)\n",
    "pyplot.ylabel('Learning Time (seconds)')\n",
    "pyplot.xlabel('Number of Threads')\n",
    "pyplot.title('XGBoost Training Speed vs Number of Threads')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see a nice trend in the decrease in execution time as the number of threads is increased. \n",
    "\n",
    "For this local execution we ran this on on a **6-core intel processor, which has a total of 12 cores: 6 physical and an additional 6 virtual cores.***\n",
    "\n",
    "#### It is interesting to note that we do not see much improvement beyond the no. of physical cores i.e. 6 threads (at about 40 seconds), after which the gains are more or less absent. \n",
    "\n",
    "The results suggest that if you have a machine with hyperthreading, you may want to set num_threads to equal the number of physical CPU cores in your machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Parallel-Cross Validation we can also compare the following scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Thread XGBoost, Parallel Thread CV: 365.254714\n"
     ]
    }
   ],
   "source": [
    "# Prepare cross validation\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "\n",
    "# Single Thread XGBoost, Parallel Thread CV\n",
    "start = time.time()\n",
    "model = XGBClassifier(nthread=1)\n",
    "results = cross_val_score(model, X, train_labels, cv=kfold, scoring='neg_log_loss', n_jobs=-1)\n",
    "elapsed = time.time() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel Thread XGBoost, Single Thread CV: 394.684315\n"
     ]
    }
   ],
   "source": [
    "# Parallel Thread XGBoost, Single Thread CV\n",
    "start = time.time()\n",
    "model = XGBClassifier(nthread=-1)\n",
    "results = cross_val_score(model, X, label_encoded_y, cv=kfold, scoring='neg_log_loss', n_jobs=1)\n",
    "elapsed = time.time() - start\n",
    "print(\"Parallel Thread XGBoost, Single Thread CV: %f\" % (elapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel Thread XGBoost and CV: 352.520111\n"
     ]
    }
   ],
   "source": [
    "# Parallel Thread XGBoost and CV\n",
    "start = time.time()\n",
    "model = XGBClassifier(nthread=-1)\n",
    "results = cross_val_score(model, X, label_encoded_y, cv=kfold, scoring='neg_log_loss', n_jobs=-1)\n",
    "elapsed = time.time() - start\n",
    "print(\"Parallel Thread XGBoost and CV: %f\" % (elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.64857141 -0.64966988 -0.65863478 -0.65553963 -0.65221448 -0.65320684\n",
      " -0.66513679 -0.64852363 -0.65310605 -0.64974786]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FEATURE IMPORTANCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
